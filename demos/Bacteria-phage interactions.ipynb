{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to match bacteria and phages via CRISPR spacers\n",
    "\n",
    "The idea here is to figure out which phages infect which bacteria by matching CRISPR spacers to phages from a database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install the necessary software\n",
    "\n",
    "We'll use [Crass](http://ctskennerton.github.io/crass/) to find CRISPR spacers in metagenomic data. The [Crass manual](http://ctskennerton.github.io/crass/assets/manual.pdf) has instructions for installation, but here's what worked on Ubuntu: \n",
    "\n",
    "* **Install Crass dependencies** \n",
    "\n",
    "```\n",
    "sudo apt-get install libxerces-c3-dev\n",
    "```\n",
    "\n",
    "```\n",
    "sudo add-apt-repository ppa:dns/gnu -y\n",
    "sudo apt-get update -q\n",
    "sudo apt-get install --only-upgrade autoconf \n",
    "```\n",
    "(or `sudo apt-get install autoconf`)\n",
    "\n",
    "```\n",
    "sudo apt install libtool-bin\n",
    "```\n",
    "\n",
    "```\n",
    "wget http://www.zlib.net/zlib-1.2.11.tar.gz\n",
    "tar -xvzf zlib-1.2.11.tar.gz \n",
    "cd zlib-1.2.11/\n",
    "./configure --prefix=/usr/local/zlib\n",
    "make\n",
    "sudo make install\n",
    "```\n",
    "\n",
    "\n",
    "* **Install Crass: download tar from [here](http://ctskennerton.github.io/crass/)**\n",
    "\n",
    "```\n",
    "tar -xf crass-0.3.12.tar.gz \n",
    "cd crass-0.3.12/\n",
    "./autogen.sh \n",
    "./configure \n",
    "make \n",
    "sudo make install\n",
    "```\n",
    "\n",
    "* **Install BLAST locally**\n",
    "\n",
    "  See the documentation [here](https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=Download) to install BLAST to run on a local machine. On Ubuntu, I followed [these instructions](https://www.ncbi.nlm.nih.gov/books/NBK52640/):\n",
    "\n",
    "  * Download the appropriate installer from ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/. For Ubuntu, download the file ending in `linux.tar.gz`.\n",
    "\n",
    "  * Move the download to the desired directory (i.e. `home`). Extract the files with `tar zxvpf ncbi-blast+2.8.1-x64-linux.tar.gz` (changing the filename to match your download).\n",
    "\n",
    "  * It's now technically usable as-is, but to be able to run from any directory, add it to the PATH: `export PATH=$PATH:$HOME/ncbi-blast-2.8.1+/bin`. If the directory isn't in the home folder, replace everything after `$PATH:$` with the correct folder. If the version number is different, change the ncbi folder name as well.\n",
    "\n",
    "  * In order to run `makeblastdb` in step 3, I also had to run `sudo apt install ncbi-blast+`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Download some microbiome data in fasta or fastq format\n",
    "\n",
    "We'll use a dataset from the Human Microbiome Project as an example. The file below is a metagenomic sample from subginvival plaque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download and extract a dataset - the data will be saved in the folder SRS014107 in the working directory\n",
    "!wget ftp://public-ftp.ihmpdcc.org/Illumina/subgingival_plaque/SRS014107.tar.bz2\n",
    "!tar -xf SRS014107.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Download reference genomes and make BLAST databases\n",
    "\n",
    "We're using an NCBI phage database and the NCBI bacteria and archaea databases, accessible by downloading the accessions from [this FTP site](ftp://ftp.ncbi.nlm.nih.gov/genomes/GENOME_REPORTS/IDS/) using `collect_accessions.py` and then downloading genome sequences using `acc2gb.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download accession numbers for phages, bacteria, and archaea\n",
    "\n",
    "!python ../parserscripts/collect_accessions.py Phages.ids > phage_accessions.txt\n",
    "!python ../parserscripts/collect_accessions.py Bacteria.ids > bacteria_accessions.txt\n",
    "!python ../parserscripts/collect_accessions.py Archaea.ids > archaea_accessions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download genome sequences \n",
    "# this takes a long time (there are ~6700 bacteria, ~280 archaea, and ~2300 phages)\n",
    "\n",
    "!cat phage_accessions.txt | python ../parserscripts/acc2gb.py your@email.com nuccore fasta > phagegenomes.dat\n",
    "!cat bacteria_accessions.txt | python ../parserscripts/acc2gb.py your@email.com nuccore fasta > bacteriagenomes.dat\n",
    "!cat archaea_accessions.txt | python ../parserscripts/acc2gb.py your@email.com nuccore fasta > archaeagenomes.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create BLAST databases: one for bacteria and archaea, one for phages\n",
    "import datetime\n",
    "today = datetime.date.today()\n",
    "\n",
    "!makeblastdb -in \"phagegenomes.dat\" -dbtype nucl -title phagedatabase_$today -out phagedb_$today\n",
    "!cat bacteriagenomes.dat archaeagenomes.dat | makeblastdb -in - -dbtype nucl -title bacdatabase_$today -out bacdb_$today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from creating a BLAST database should look something like this:\n",
    "\n",
    "```\n",
    "Building a new DB, current time: 05/11/2018 12:37:11\n",
    "New DB name:   /Documents/GitHub/phageParser/bacdb_May2018\n",
    "New DB title:  bacdatabase_May2018\n",
    "Sequence type: Nucleotide\n",
    "Keep Linkouts: T\n",
    "Keep MBits: T\n",
    "Maximum file size: 1000000000B\n",
    "Adding sequences from FASTA; added 6990 sequences in 103.433 seconds.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Crass\n",
    "\n",
    "The simplest syntax to run Crass on a fasta file is `crass input_fasta_file -o output_directory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change data_ID to the folder name of the dataset downloaded in step 2.\n",
    "data_ID = \"SRS014107\"\n",
    "crass_output_directory = \"%s-crass-output\" %data_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[crass_patternFinder]: Processed 4258293 ...21 sec\n",
      "[crass_clusterCore]: 792 variants mapped to 291 clusters\n",
      "[crass_clusterCore]: creating non-redundant set\n",
      "[crass_clusterCore]: 1000 non-redundant patterns.\n",
      "[crass_singletonFinder]: Processed 4258293 ...17 sec\n",
      "[crass_patternFinder]: Found 130586 reads\n",
      "[crass_graphBuilder]: 33 CRISPRs found!\n"
     ]
    }
   ],
   "source": [
    "# Run Crass on the downloaded file from earlier\n",
    "!crass \"$data_ID/$data_ID\".denovo_duplicates_marked.trimmed.1.fastq -o $crass_output_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Parse Crass output to get spacer sequences\n",
    "\n",
    "The Crass output we're interested in is the file `crass.crispr` that appears in the output directory. It's an XML file, so we can parse it. \n",
    "\n",
    "Setup:\n",
    "* create a folder called `spacers` in the Crass output folder\n",
    "* create a folder called `source_reads` in the Crass output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘SRS014107-crass-output/spacers’: File exists\n",
      "mkdir: cannot create directory ‘SRS014107-crass-output/source_reads’: File exists\n"
     ]
    }
   ],
   "source": [
    "# create a folder called 'spacers' and a folder called 'source_reads in the Crass output folder'\n",
    "\n",
    "!mkdir \"$crass_output_directory\"/spacers\n",
    "!mkdir \"$crass_output_directory\"/source_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('%s/crass.crispr' %crass_output_directory)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dictionary to store repeats and read headers to get them out of the original file later\n",
    "read_dict = {}\n",
    "\n",
    "# create a list of the accessions that come up\n",
    "read_dict_accessions = {}\n",
    "    \n",
    "for child in root: # each top-level child is a CRISPR array\n",
    "    repeat = child.attrib['drseq'] # the consensus repeat sequence identified by Crass\n",
    "    spacers = child[0][2] # the spacers associated with that repeat\n",
    "    source_reads = child[0][0] # the source reads that the spacers and repeats come from\n",
    "    \n",
    "    read_dict[repeat] = {}\n",
    "    \n",
    "    # create a file with the spacers\n",
    "    \n",
    "    with open(crass_output_directory + \"/spacers/\" + repeat + \".fasta\", 'w') as spacer_file:\n",
    "        for spacer in spacers:\n",
    "            spacer_file.write('>' + spacer.attrib['spid'] + '\\n')\n",
    "            spacer_file.write(spacer.attrib['seq'] + '\\n')\n",
    "    \n",
    "    for read in source_reads:\n",
    "        header = read.attrib['accession']\n",
    "        read_dict[repeat][header] = []\n",
    "        read_dict_accessions[header] = repeat\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the sequences associated with each repeat for BLASTing\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_record in SeqIO.parse(data_ID + \"/SRS014107.denovo_duplicates_marked.trimmed.1.fastq\", \"fastq\"):\n",
    "    header = seq_record.id \n",
    "    if header in read_dict_accessions.keys():\n",
    "        read_dict[read_dict_accessions[header]][header] = seq_record.seq\n",
    "    #print(repr(seq_record.seq))\n",
    "    #print(len(seq_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save sequences to a file, one for each repeat\n",
    "\n",
    "for repeat in read_dict.keys():\n",
    "    with open(crass_output_directory + \"/source_reads/\" + repeat +'_reads' + \".fasta\", 'w') as repeat_file:\n",
    "        for header, sequence in read_dict[repeat].items():\n",
    "            repeat_file.write('>' + header + '\\n')\n",
    "            repeat_file.write(str(sequence) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: BLAST spacers against phage database, BLAST source reads against bacterial database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Parse BLAST output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Create interaction matrix"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:django]",
   "language": "python",
   "name": "conda-env-django-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
